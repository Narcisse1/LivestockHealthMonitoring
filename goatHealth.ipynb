{
 "cells": [
  {
   "metadata": {},
   "cell_type": "raw",
   "source": "",
   "id": "f3fa63d8159939f4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T22:47:41.265423Z",
     "start_time": "2025-06-24T22:47:41.232219Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import logging\n",
    "\n",
    "# Set up logging to track invalid files\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ],
   "id": "13a9347eea500c54",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T22:47:41.596826Z",
     "start_time": "2025-06-24T22:47:41.436926Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1. Define paths and parameters\n",
    "DATASET_PATH = \"D:\\\\goats\"  # Your dataset path\n",
    "IMG_SIZE = (224, 224)  # Standard size for CNNs\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 20\n",
    "LEARNING_RATE = 0.001\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "id": "74214117283510c0",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T22:47:41.666638Z",
     "start_time": "2025-06-24T22:47:41.629842Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 2. Define data transforms\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(IMG_SIZE),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Resize(IMG_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ],
   "id": "54defdea4dee8f50",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T22:48:14.318233Z",
     "start_time": "2025-06-24T22:47:41.890530Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 3. Validate images\n",
    "def verify_image(img_path):\n",
    "    try:\n",
    "        img = Image.open(img_path)\n",
    "        img.verify()  # Verify image integrity\n",
    "        img = Image.open(img_path)  # Re-open for format check\n",
    "        img.convert(\"RGB\")  # Ensure it can be converted to RGB\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Invalid image: {img_path}, Error: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "# 4. Load dataset and filter invalid images\n",
    "dataset = ImageFolder(root=DATASET_PATH, transform=val_test_transform)\n",
    "valid_samples = [(path, label) for path, label in dataset.samples if verify_image(path)]\n",
    "if len(valid_samples) < len(dataset.samples):\n",
    "    logging.warning(f\"Filtered out {len(dataset.samples) - len(valid_samples)} invalid images\")\n",
    "dataset.samples = valid_samples"
   ],
   "id": "ed5fa328c8fe30fd",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Invalid image: D:\\goats\\healthy_goat\\healthy goat_446.jpeg, Error: cannot identify image file 'D:\\\\goats\\\\healthy_goat\\\\healthy goat_446.jpeg'\n",
      "WARNING: Filtered out 1 invalid images\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T23:10:07.176771Z",
     "start_time": "2025-06-24T23:10:06.550409Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 5. Split dataset into train, validation, and test sets\n",
    "labels = np.array([label for _, label in dataset.samples])\n",
    "indices = np.arange(len(dataset))\n",
    "train_idx, temp_idx, _, temp_labels = train_test_split(\n",
    "    indices, labels, test_size=0.3, stratify=labels, random_state=42\n",
    ")\n",
    "val_idx, test_idx = train_test_split(\n",
    "    temp_idx, test_size=0.5, stratify=temp_labels, random_state=42\n",
    ")\n",
    "\n",
    "# Create subsets for train, validation, and test\n",
    "train_dataset = Subset(dataset, train_idx)\n",
    "val_dataset = Subset(dataset, val_idx)\n",
    "test_dataset = Subset(dataset, test_idx)\n",
    "\n",
    "# Apply training transforms to train_dataset\n",
    "train_dataset.dataset.transform = train_transform\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# 6. Define the CNN model\n",
    "class GoatCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GoatCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * 28 * 28, 128)  # Adjust based on image size\n",
    "        self.fc2 = nn.Linear(128, 1)  # Binary classification\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = self.pool(self.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 64 * 28 * 28)  # Flatten\n",
    "        x = self.dropout(self.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ],
   "id": "7fc5333698baae2",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T23:10:23.979706Z",
     "start_time": "2025-06-24T23:10:23.824755Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 7. Initialize model, loss function, and optimizer\n",
    "model = GoatCNN().to(DEVICE)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# 8. Training loop\n",
    "def train_model():\n",
    "    best_val_loss = float('inf')\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        # Training\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE).float().unsqueeze(1)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * images.size(0)\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_preds, val_labels = [], []\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(DEVICE), labels.to(DEVICE).float().unsqueeze(1)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item() * images.size(0)\n",
    "                val_preds.extend(torch.sigmoid(outputs).cpu().numpy().flatten() > 0.5)\n",
    "                val_labels.extend(labels.cpu().numpy().flatten())\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        val_accuracy = accuracy_score(val_labels, val_preds)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{NUM_EPOCHS}, Train Loss: {train_loss:.4f}, \"\n",
    "              f\"Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "        # Save best model\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), \"goat_classifier.pth\")\n"
   ],
   "id": "7f72b090b15b29ab",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T23:10:05.227009Z",
     "start_time": "2025-06-24T22:48:14.755879Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 9. Evaluate on test set\n",
    "def evaluate_model():\n",
    "    model.load_state_dict(torch.load(\"goat_classifier.pth\"))\n",
    "    model.eval()\n",
    "    test_preds, test_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE).float().unsqueeze(1)\n",
    "            outputs = model(images)\n",
    "            test_preds.extend(torch.sigmoid(outputs).cpu().numpy().flatten() > 0.5)\n",
    "            test_labels.extend(labels.cpu().numpy().flatten())\n",
    "\n",
    "    print(\"\\nTest Set Evaluation:\")\n",
    "    print(f\"Accuracy: {accuracy_score(test_labels, test_preds):.4f}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(test_labels, test_preds, target_names=[\"Healthy\", \"Unhealthy\"]))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(test_labels, test_preds))\n",
    "\n",
    "# 10. Run training and evaluation\n",
    "if __name__ == \"__main__\":\n",
    "    print(f\"Using device: {DEVICE}\")\n",
    "    print(f\"Train samples: {len(train_dataset)}, Val samples: {len(val_dataset)}, Test samples: {len(test_dataset)}\")\n",
    "    train_model()\n",
    "    evaluate_model()"
   ],
   "id": "f436bc71d53fe27f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Train samples: 648, Val samples: 139, Test samples: 140\n",
      "Epoch 1/20, Train Loss: 0.8267, Val Loss: 0.6723, Val Accuracy: 0.5180\n",
      "Epoch 2/20, Train Loss: 0.6857, Val Loss: 0.6731, Val Accuracy: 0.5827\n",
      "Epoch 3/20, Train Loss: 0.6524, Val Loss: 0.6039, Val Accuracy: 0.6763\n",
      "Epoch 4/20, Train Loss: 0.5988, Val Loss: 0.5497, Val Accuracy: 0.6978\n",
      "Epoch 5/20, Train Loss: 0.5279, Val Loss: 0.6013, Val Accuracy: 0.6331\n",
      "Epoch 6/20, Train Loss: 0.5481, Val Loss: 0.4535, Val Accuracy: 0.7698\n",
      "Epoch 7/20, Train Loss: 0.4506, Val Loss: 0.3416, Val Accuracy: 0.8489\n",
      "Epoch 8/20, Train Loss: 0.3886, Val Loss: 0.2966, Val Accuracy: 0.9065\n",
      "Epoch 9/20, Train Loss: 0.3486, Val Loss: 0.2106, Val Accuracy: 0.9424\n",
      "Epoch 10/20, Train Loss: 0.2937, Val Loss: 0.2691, Val Accuracy: 0.9209\n",
      "Epoch 11/20, Train Loss: 0.2594, Val Loss: 0.1659, Val Accuracy: 0.9137\n",
      "Epoch 12/20, Train Loss: 0.2597, Val Loss: 0.1848, Val Accuracy: 0.9353\n",
      "Epoch 13/20, Train Loss: 0.2103, Val Loss: 0.1355, Val Accuracy: 0.9424\n",
      "Epoch 14/20, Train Loss: 0.1933, Val Loss: 0.1140, Val Accuracy: 0.9568\n",
      "Epoch 15/20, Train Loss: 0.1439, Val Loss: 0.0815, Val Accuracy: 0.9712\n",
      "Epoch 16/20, Train Loss: 0.1609, Val Loss: 0.0879, Val Accuracy: 0.9568\n",
      "Epoch 17/20, Train Loss: 0.1278, Val Loss: 0.0914, Val Accuracy: 0.9424\n",
      "Epoch 18/20, Train Loss: 0.1240, Val Loss: 0.0801, Val Accuracy: 0.9496\n",
      "Epoch 19/20, Train Loss: 0.1493, Val Loss: 0.1089, Val Accuracy: 0.9353\n",
      "Epoch 20/20, Train Loss: 0.1198, Val Loss: 0.0821, Val Accuracy: 0.9496\n",
      "\n",
      "Test Set Evaluation:\n",
      "Accuracy: 0.9714\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Healthy       0.98      0.95      0.97        66\n",
      "   Unhealthy       0.96      0.99      0.97        74\n",
      "\n",
      "    accuracy                           0.97       140\n",
      "   macro avg       0.97      0.97      0.97       140\n",
      "weighted avg       0.97      0.97      0.97       140\n",
      "\n",
      "Confusion Matrix:\n",
      "[[63  3]\n",
      " [ 1 73]]\n"
     ]
    }
   ],
   "execution_count": 15
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
